# üöÄ AI Projects Portfolio ‚Äì by a 16-Year-Old Innovator

![GitHub Repo Size](https://img.shields.io/github/repo-size/FWKMultiverse/FWK-Multiverse)
![GitHub stars](https://img.shields.io/github/stars/FWKMultiverse/FWK-Multiverse)
![GitHub license](https://img.shields.io/github/license/FWKMultiverse/FWK-Multiverse)
![Python](https://img.shields.io/badge/python-3.11-blue)
![AI](https://img.shields.io/badge/AI-MultiAgent-green)
![RL](https://img.shields.io/badge/Reinforcement-Learning-orange)
![LLM](https://img.shields.io/badge/LLM-CodeGen-purple)
![GNN](https://img.shields.io/badge/GNN-GraphNeuralNetwork-purple)
![RAG](https://img.shields.io/badge/RAG-VectorSearch-red)
![PyTorch](https://img.shields.io/badge/PyTorch-Framework-red)
![TensorFlow](https://img.shields.io/badge/TensorFlow-Framework-orange)
![Keras](https://img.shields.io/badge/Keras-DeepLearning-red)
![LightGBM](https://img.shields.io/badge/LightGBM-ML-green)
![CatBoost](https://img.shields.io/badge/CatBoost-ML-blue)
![GaussianProcess](https://img.shields.io/badge/GaussianProcess-ML-lightgrey)
![Scikit-Learn](https://imgshields.io/badge/Scikit--Learn-ML-yellow)
![Optuna](https://img.shields.io/badge/Optuna-Hyperparameter-lightgrey)
![AsyncIO](https://img.shields.io/badge/AsyncIO-Concurrent-lightblue)
![Joblib](https://img.shields.io/badge/Joblib-Parallel-lightgreen)
![Pandas](https://img.shields.io/badge/Pandas-Dataframe-blue)
![NumPy](https://img.shields.io/badge/NumPy-Array-lightblue)
![Shap](https://img.shields.io/badge/SHAP-ExplainableAI-orange)
![PyTorch Geometric](https://img.shields.io/badge/PyG-GraphNeuralNetwork-purple)
![Transformers](https://img.shields.io/badge/Transformers-NLP-blue)
![Datasets](https://img.shields.io/badge/Datasets-HuggingFace-lightblue)
![Accelerate](https://img.shields.io/badge/Accelerate-Training-purple)
![Docker](https://img.shields.io/badge/Docker-Sandbox-blue)
![MultiAgent](https://img.shields.io/badge/MultiAgent-System-green)
![Trading](https://img.shields.io/badge/Trading-Forex/Crypto-yellow)
![Numerai](https://img.shields.io/badge/Numerai-Challenge-darkblue)
![Private](https://img.shields.io/badge/Code-Private-red)
![Research](https://img.shields.io/badge/Research-Level-purple)

---

## üåü Introduction

Welcome to my portfolio. I'm a **16-year-old self-taught AI developer** with a formal education up to grade 9. My journey is driven by a singular passion: to build **complex, intelligent systems** that solve real-world problems. Instead of following a traditional learning path, I dive headfirst into creating **full-scale, resilient, and research-level AI systems**.

This document is not merely a list of projects; it's a testament to my architectural philosophy, my problem-solving approach, and my vision for the future of AI. The code for these projects remains **private**, as they represent my core intellectual property. However, the detailed descriptions here aim to provide a transparent and comprehensive look into the technical depth of my work.

‚ö†Ô∏è **Important Note:** All systems presented here are **original concepts**, architected and built independently by me. This is a high-level overview intended for technical evaluation, not an implementation guide.

---

## üíñ A Call for Support: Powering the Next Wave of AI Innovation

To push the boundaries of what's possible, especially in fields like **Reinforcement Learning** and **Large Language Models**, computational power isn't just a facilitator‚Äîit's a fundamental requirement. Currently, my progress is constrained by the limitations of my existing hardware.

**As a newcomer, I've poured my efforts into designing these advanced architectures, but due to significant resource constraints‚Äîspecifically low GPU power and insufficient RAM‚ÄîI'm currently unable to run these complex systems to generate and showcase concrete results.** The theory and architecture are solid, but the practical execution is bottlenecked.

This is precisely why **I'm seeking financial support: to upgrade my computer.**

A more powerful machine, equipped with a high-end GPU, will directly enable me to:
1.  **Train More Complex Models:** My current setup struggles with the VRAM and processing demands of larger models. An upgrade would allow for training larger, more capable agents and exploring state-of-the-art architectures.
2.  **Accelerate Research & Development:** Iteration speed is critical in AI. Faster training cycles mean I can experiment with more hypotheses, fine-tune models more effectively, and ultimately innovate at a much faster pace.
3.  **Produce Demonstrable Results:** With adequate hardware, I can finally run my systems at their full potential and generate concrete, shareable results‚Äîsuch as live trading performance, Numerai competition rankings, and interactive demos. This moves my work from theoretical architecture to proven application.

Your support would be a direct investment in my potential and would be instrumental in unlocking the next stage of my projects. Every contribution, big or small, makes a significant difference.

[![Sponsor](https://img.shields.io/badge/Sponsor-My_AI_Research_on_GitHub-green)](https://github.com/sponsors/FWKMultiverse)
**Direct Link to Sponsor:** [https://github.com/sponsors/FWKMultiverse](https://github.com/sponsors/FWKMultiverse)

---

## üè∑Ô∏è Tags for Visibility & Areas of Interest

`AI` `Reinforcement Learning` `Multi-Agent Systems` `Large Language Models (LLM)` `Generative AI` `Graph Neural Networks (GNN)` `Retrieval-Augmented Generation (RAG)` `Quantitative Finance` `Algorithmic Trading` `AI for Games` `Explainable AI (XAI)` `AutoML` `Robust Systems` `High-Performance Computing` `AI Research`

**Companies & Research Labs:**
`OpenAI` `DeepMind` `Google Research` `Google Brain` `Jane Street` `NVIDIA` `Microsoft Research` `GitHub Copilot` `Unity` `Epic Games (Unreal Engine)` `High-Level AI/Tech Startups`

---

## üìÇ Projects Overview

My work is concentrated into three core projects, each developed with a specific, ambitious goal in mind:

1.  **AI Trading System** ‚Äì 28 days (A production-grade, multi-agent system for real-time financial markets.)
2.  **Numerai Competition System** ‚Äì 6 days (An expert-level, ensemble-of-ensembles architecture for a leading data science tournament.)
3.  **Multi-Agent LLM for Game Development** ‚Äì 8 days (A cutting-edge, research-frontier system emulating a full AI software development team.)

Each project is detailed extensively below.

---

## 1Ô∏è‚É£ Project 1: AI Trading System

**Timeline:** 28 Days
**Level:** Production-Grade / Professional
**Core Technologies:** Python, Async I/O, Multi-Agent Reinforcement Learning (MARL), Transformers, GNN, Flask, SHAP (XAI)

### üìù In-Depth Project Overview
This system is an **end-to-end, fully automated AI trading platform** designed for the high-frequency, chaotic environments of Forex and Cryptocurrency markets. The core architectural philosophy is modularity and resilience, creating a system that can operate 24/7 with minimal human intervention. It's structured into a robust three-tier architecture:

-   **Tier 1: Fetcher (`fetcher.py`)**: The system's sensory organ. This asynchronous module is responsible for ingesting a wide array of data streams in real-time. It doesn't just pull price data; it gathers economic news, scrapes social media sentiment, and queries Google Search trends to gauge market psychology. Its design is hyper-focused on reliability.
-   **Tier 2: AI Server (`AIServer.py`)**: The central nervous system. Built on **Flask**, this web server acts as the command and control center. It manages a sophisticated asynchronous task queue, ensuring that requests for trading signals and commands to retrain models are handled gracefully without blocking critical operations.
-   **Tier 3: AI Engine (`AIEngine.py`)**: The brain of the operation. It takes the processed data from the Fetcher, performs deep analysis, and leverages a society of specialized AI agents to generate a final, high-conviction trading signal.

### ü§ñ Multi-Agent Architecture & Advanced Models
The system's intelligence is not monolithic. It's a collaborative **Multi-Agent Reinforcement Learning (MARL)** ecosystem where each agent possesses a unique expertise, mimicking a team of human analysts.

1.  **The Macro Agent (The Strategist)**: Analyzes the market from a bird's-eye view (H1, H4, Daily). It uses classical indicators, **News Embeddings** from a Transformer, and **Graph Embeddings** from a GNN to determine the overall market regime: Bullish, Bearish, or Consolidation.

2.  **The Micro Agent (The Executioner)**: The primary decision-maker for market entry and exit (M5, M15). It takes the strategic context from the Macro Agent as a critical input. Its core is a **Transformer Block**, allowing it to analyze time-series data with an attention mechanism to capture complex patterns.

3.  **The Risk Agent (The Manager)**: Purely for risk management. It constantly monitors the portfolio's state (P/L, Equity, Drawdown) and dynamically adjusts the position sizing for trades suggested by the Micro Agent, ensuring catastrophic losses are avoided.

**Supporting Models:**
-   **Graph Neural Network (GNN) Analyzer**: Creates a dynamic graph of assets and their correlations, generating a "Graph Embedding"‚Äîa rich summary of the market's interconnectedness for the Macro Agent.
-   **News Transformer**: A fine-tuned NLP model that processes news headlines, converting unstructured text into dense "News Embeddings" that capture sentiment and thematic shifts.

### üõ°Ô∏è Uncompromising Error Handling & Reliability
A trading system is only as good as its uptime. This system was built with a "fail-safe" mentality.
-   **Retry with Exponential Backoff**: A decorator `@retry_async` wraps all external API calls, gracefully handling temporary network issues.
-   **API Cooldown & Quota Management**: The system intelligently tracks API usage and places failing endpoints in a temporary "cooldown" to prevent being blacklisted.
-   **Asynchronous Task Queues**: The AIServer uses `ThreadPoolExecutor` to offload long-running tasks like model training, ensuring the main server remains responsive.
-   **Request Timeouts**: The `/get_signal` endpoint has a strict timeout, preventing the client from hanging indefinitely.
-   **Automated Data Sanitization**: A startup function, `clean_corrupt_json_files`, scans for and removes malformed files that could crash the training process.

### üåü Unique & Innovative Features
-   **Explainable AI (XAI) with SHAP**: I integrated the `shap` library to visualize which features contributed most to the Micro Agent's decision to buy or sell.
-   **Advanced Risk Management with Kelly Criterion**: The system includes a function based on the Kelly Criterion to determine optimal position size and maximize long-term growth.
-   **Multi-Timeframe Fusion**: Seamless integration of analysis from M5 up to Daily charts gives the AI a holistic market perspective.

---

## 2Ô∏è‚É£ Project 2: Numerai Competition System

**Timeline:** 6 Days (Rapid Development Sprint)
**Level:** Expert / Research-Grade
**Core Technologies:** Python, LightGBM, CatBoost, GNN, Transformer, LSTM, Autoencoder, Gaussian Processes, Optuna

### üìù In-Depth Project Overview
This project was an intensive effort to build a top-tier system for the **Numerai Tournament**, a challenge to predict stock market returns from obfuscated data. The strategy was to architect a massively complex **ensemble-of-ensembles** system to maximize predictive power and robustness under a tight deadline.

-   **`data_converter.py`**: A highly efficient pre-processing script that transforms raw Parquet data into a more manageable Era-grouped JSON format, drastically speeding up data loading.
-   **`AInumerai_Ultra.py`**: The monolithic core of the project. It orchestrates the entire pipeline: feature engineering, parallel training of over a dozen model configurations, hyperparameter optimization, and multi-layer ensembling.
-   **`CSVP.py`**: A custom validation tool that simulates Numerai's unique scoring system locally for rapid iteration.

### ü§ñ A Symphony of Models: The Ensemble-of-Ensembles Architecture
The system's power comes from its diversity, combining models that approach the problem in fundamentally different ways.

-   **Gradient Boosting Powerhouses (LightGBM & CatBoost)**: The workhorses, skilled at finding patterns in large tabular datasets.
-   **Graph Neural Network + Transformer Hybrid**: This innovative model treats features as nodes in a graph. The GNN learns the relational structure, and a Transformer learns which features deserve the most "attention".
-   **Temporal Model (LSTM)**: Processes data era-by-era to capture temporal dependencies and regime changes.
-   **Unsupervised Feature Extractor (Autoencoder)**: A neural network that compresses input features into a small latent space, creating a powerful new feature for other models.
-   **Multi-Agent RL Decider**: Takes predictions from the GNN, LGBM, and Temporal models as its "state" and learns an optimal policy for combining them.

**Meta-Models for Final Blending:**
-   **Ridge Regression for Neutralization**: A key technique to create predictions that are uncorrelated with known risk factors.
-   **Gaussian Process Regressor**: The final aggregator. This probabilistic model takes the outputs of *all* other models and produces the final submission with uncertainty estimates.

### üõ°Ô∏è Robustness Under Pressure
-   **Graceful Degradation**: The code checks for optional heavy libraries. If they aren't installed, the system falls back to a simpler but functional mode instead of crashing.
-   **Aggressive Memory Management**: A `reduce_memory_usage` function downcasts data types to drastically reduce RAM consumption.
-   **Parallel Seed Training**: The entire training process is wrapped in `multiprocessing`, training the same model on multiple different random seeds simultaneously to create a more stable final result.

### üåü Competition-Winning Features
-   **Automated Hyperparameter Tuning**: Uses **Optuna** for tree-based models and **Keras Tuner** for neural networks to automate one of the most time-consuming parts of machine learning.
-   **Adversarial Validation**: A classifier is trained to distinguish between training and validation data. Features that make this distinction easy are considered "unstable" and are down-weighted.
-   **Purged Time-Series Cross-Validation**: A strict walk-forward validation strategy that prevents any data from the future from leaking into the training of a model.

---

## 3Ô∏è‚É£ Project 3: Multi-Agent LLM for Game Development

**Timeline:** 8 Days
**Level:** Advanced R&D / Research Frontier
**Core Technologies:** Python, PPO-RL, LLMs (Salesforce/codegen-2B-mono), LoRA Fine-Tuning, GNN, RAG, Docker

### üìù In-Depth Project Overview
This is my most ambitious project: a self-contained **AI Agent Swarm**, powered by a Large Language Model, designed to function as an autonomous game development assistant. The system can understand an entire codebase, write new code, fix bugs, refactor existing code, and even contribute to game design.

### ü§ñ An Ecosystem of Specialized LLM Agents
The foundation is a single, powerful LLM (`Salesforce/codegen-2B-mono`), which is then specialized into a multitude of "expert" agents using efficient fine-tuning techniques.

-   **Core Model Technology**:
    -   **4-bit Quantization (BitsAndBytes)**: Drastically reduces the model's memory footprint, allowing a 2-billion-parameter model to run on consumer GPUs.
    -   **LoRA (Low-Rank Adaptation)**: An efficient fine-tuning method where only small "adapter" layers are trained, saving immense time and computational resources.

-   **The Agent Swarm (>10 Specialized Agents)**:
    -   **Code Generation & Refinement**: `CodeGeneratorAgent`, `CodeRefinementAgent`, `AutoRefactoringAgent`.
    -   **Analysis & Critique**: `CodeCriticAgent`, `BugReportGeneratorAgent`, `CodeSummarizationAgent`.
    -   **Testing & Documentation**: `TestGenerationAgent`, `DocumentationAgent`.
    -   **Creative & Planning**: `AssetGeneratorAgent`, `GameDesignerAgent`.
    -   **Knowledge Retrieval**: `CodeQuestionAnsweringAgent`.

### üõ°Ô∏è Security-First Error Handling and Code Execution
Running AI-generated code is inherently risky. This project's most critical feature is its multi-layered security protocol.
-   **Sandboxed Code Execution with Docker**: The cornerstone of safety. Every piece of AI-generated code is executed inside a heavily restricted, ephemeral **Docker Container**. This container has no network access and is limited in CPU and RAM usage, completely isolating it from the host system.
-   **Multi-layered Security Audits**: Before execution, code undergoes a rigorous automated audit:
    1.  **Static Analysis**: `luacheck` is used to find syntax errors.
    2.  **Pattern Matching**: Regular expressions scan for dangerous patterns like `os.execute`.
    3.  **Vulnerability Scanning**: The code is checked for common vulnerability patterns.

### üåü The Research Frontier: Advanced AI Techniques
-   **Knowledge Graph-Augmented LLM**: The system's most profound innovation. The entire game codebase is parsed into an **Abstract Syntax Tree (AST)** and converted into a **Knowledge Graph**. This graph is processed by a GNN, and the resulting embedding is injected into the LLM's context. This gives the LLM a holistic, structural understanding of the entire project.
-   **Retrieval-Augmented Generation (RAG)**: The system maintains a `VectorizedMemory` of high-quality code snippets. When a new task arrives, relevant agents perform a similarity search to retrieve the most relevant examples, providing them to the LLM as "inspiration" to dramatically improve the quality of generated code.
-   **Fine-tuning with Reinforcement Learning (PPO)**: Agents learn through trial and error. The `CodeEvaluator` (running in the secure Docker sandbox) acts as the RL "environment," providing a "reward" based on whether the generated code runs and passes tests. Agents are then fine-tuned using **PPO** to maximize this reward.
-   **Prioritized Experience Replay (PER)**: A sophisticated learning buffer that allows agents to learn more efficiently by focusing on the mistakes that were most surprising or led to the biggest errors.
-   **Sequential Fine-tuning Pipeline**: The `main` function is designed as a curriculum, allowing the system to first master Roblox development, then sequentially learn Godot, Unity, and Unreal Engine.

---

## üí° Vision & Philosophy

My approach is to build systems that are not just academically interesting but are architected with the robustness required for real-world application. I believe in learning by building complex, end-to-end projects that force me to solve practical problems in reliability, scalability, and efficiency.

-   **Build First, Theorize Later**: I learn best by tackling ambitious, large-scale projects directly.
-   **Resilience is a Feature**: A system that cannot gracefully handle failure is incomplete.
-   **AI Must Be Transparent**: I strive to build systems that are explainable (XAI), not opaque black boxes.
-   **Compound Growth**: Each project serves as a foundation of knowledge and tools for the next, more ambitious endeavor.

---

## üì¨ Contact

I'm actively seeking opportunities and collaborations. Let's connect.
-   üìß **Email:** [yoglawm644@gmail.com](mailto:yoglawm644@gmail.com)
-   üåê **Facebook Page:** [FWK Multiverse](https://www.facebook.com/FWKMultiverse/)
-   üê¶ **Twitter/X:** [@FWK_Multiverse](https://x.com/FWK_Multiverse)

---

> ‚ö° Thank you for taking the time to review my work. This portfolio is a living document that will evolve as I continue to build and innovate.
